{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import expipe\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import spatial_maps.stats as stats\n",
    "import pnnmec.data_processing as dp\n",
    "import head_direction.head as head\n",
    "import spatial_maps as sp\n",
    "import pnnmec.registration\n",
    "import speed_cells.speed as spd\n",
    "import pnnmec.spikes as spikes\n",
    "#import pnnmec.version_control as vc\n",
    "import re\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pnnmec\n",
    "import scipy.ndimage.measurements\n",
    "# Progress bars for pandas\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed = 100, # m/s only used for speed score\n",
    "min_speed = 2, # m/s only used for speed score\n",
    "position_sampling_rate = 100 # for interpolation\n",
    "position_low_pass_frequency = 6 # for low pass filtering of position\n",
    "\n",
    "box_size = 1.0\n",
    "bin_size = 0.02\n",
    "smoothing_low = 0.03\n",
    "smoothing_high = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set `CHARLOTTE_PNN_MEC_DATA` in your environment before running `jupyter notebook`:\n",
    "\n",
    "```\n",
    "export CHARLOTTE_PNN_MEC_DATA=/path/to/data\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Then you can continue running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = dp.project_path()\n",
    "\n",
    "project = expipe.get_project(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create action for this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_variability = project.require_action(\"field_variability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load related sessions action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relate_sessions = project.actions['relate_sessions']\n",
    "relate_sessions.data['same-day-familiar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relate_sessions = project.actions['relate_sessions']\n",
    "\n",
    "# TODO create helper function that does this\n",
    "data_path = pathlib.Path(project_path) / \"actions\" / relate_sessions.id / \"data\" / relate_sessions.data['same-day-familiar']\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv(data_path)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[~table['session_1'].str.contains(\"z:\")]\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(action_id, channel_id, unit_id):\n",
    "    global data_cache\n",
    "    unique_id = hash((action_id, channel_id, unit_id))\n",
    "    \n",
    "    data_path = pathlib.Path(project_path) / \"actions\" / action_id / \"data\" / \"main.exdir\"\n",
    "    unit_path = \"/processing/electrophysiology/channel_group_{}/UnitTimes/{}\".format(\n",
    "        channel_id,                                                          \n",
    "        unit_id\n",
    "    )\n",
    "    print(\"Loading\", data_path, channel_id, unit_id)\n",
    "    if unique_id in data_cache:\n",
    "        print(\"Using result from cache\")\n",
    "        return data_cache[unique_id]\n",
    "    \n",
    "#     unit_path = \"{}/{}/\".format(channel_id, unit_id)\n",
    "#     position_path = \"position_data/\"\n",
    "    \n",
    "    root_group = exdir.File(data_path, plugins=[exdir.plugins.quantities,\n",
    "                                                exdir.plugins.git_lfs.Plugin(verbose=True)])\n",
    "    unit_group = root_group[unit_path]\n",
    "\n",
    "    # tracking data\n",
    "    position_group = root_group['processing']['tracking']['camera_0']['Position']\n",
    "    stop_time = position_group.attrs.to_dict()[\"stop_time\"]\n",
    "    # stop_time = 100\n",
    "    # print(stop_time)\n",
    "    # stop_time = 100. # TODO remove\n",
    "    def get_raw_position(spot_group):\n",
    "        coords = spot_group[\"data\"]\n",
    "        t = spot_group[\"timestamps\"].data\n",
    "        x = coords[:, 0]\n",
    "        y = coords[:, 1]\n",
    "        return x, y, t\n",
    "    \n",
    "    x1, y1, t1 = tr.get_raw_position(position_group['led_0'])\n",
    "    x2, y2, t2 = tr.get_raw_position(position_group['led_1'])\n",
    "    x, y, t = tr.select_best_position(x1, y1, t1, x2, y2, t2)\n",
    "    x, y, t = tr.interp_filt_position(x, y, t, pos_fs=par['pos_fs'], f_cut=par['f_cut'])\n",
    "    mask = t <= stop_time\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    t = t[mask]\n",
    "    \n",
    "    dt = np.mean(np.diff(t))\n",
    "    vel = np.gradient([x,y],axis=1)/dt\n",
    "    speed = np.linalg.norm(vel,axis=0)\n",
    "\n",
    "    # spiketrain data\n",
    "    sptr_group = unit_group \n",
    "    metadata = {}\n",
    "    times = pq.Quantity(sptr_group['times'].data,\n",
    "                        sptr_group['times'].attrs['unit'])\n",
    "    t_stop = sptr_group.parent.attrs['stop_time']\n",
    "    t_start = sptr_group.parent.attrs['start_time']\n",
    "    metadata.update(sptr_group['times'].attrs.to_dict())\n",
    "    metadata.update({'exdir_path': str(data_path)})\n",
    "    sptr = neo.SpikeTrain(times=times,\n",
    "                      t_stop=t_stop,\n",
    "                      t_start=t_start,\n",
    "                      waveforms=None,\n",
    "                      sampling_rate=None,\n",
    "                      **metadata)\n",
    "    \n",
    "    data_cache[unique_id] = (x, y, t, speed, sptr)\n",
    "    return x, y, t, speed, sptr\n",
    "\n",
    "# first_row = table.iloc[0]\n",
    "first_row = table[table['session_1'] == \"1528-140115-01\"][table['group'] == 3][table['unit'] == 4].iloc[0]\n",
    "\n",
    "x, y, t, speed, sptr = load_data(first_row['session_1'], first_row['group'], first_row['unit'])\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_map(x, y, t, speed, sptr):\n",
    "    rate_map = tr.spatial_rate_map(x, y, t, sptr, \n",
    "                                   binsize=par['spat_binsize'],\n",
    "                                   smoothing=0.06,\n",
    "                                   mask_unvisited=False, \n",
    "                                   convolve = True)\n",
    "    \n",
    "    #rate_map = sp.rate_map(x, y, t, sptr, box_size=1.0, bin_size=0.03, smoothing=5)\n",
    "    \n",
    "    return rate_map\n",
    "    \n",
    "rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "plt.imshow(rate_map.T, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_map(x, y, t, speed, sptr):    \n",
    "#     rate_map = sp.rate_map(x, y, t, sptr, box_size=1.0, bin_size=0.02, smoothing=5)\n",
    "\n",
    "    spatial_map = sp.SpatialMap(x, y, t.magnitude, sptr, box_size=1.0, bin_size=0.02)\n",
    "    rate_map = spatial_map.rate_map(smoothing=0.05)\n",
    "    \n",
    "    return rate_map\n",
    "    \n",
    "rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "plt.imshow(rate_map.T, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_autocorrelation(rate_map):\n",
    "    return exana.misc.tools.fftcorrelate2d(rate_map, rate_map, mode='full', normalize=True)\n",
    "\n",
    "autocorrelation = calculate_autocorrelation(rate_map)\n",
    "\n",
    "plt.imshow(autocorrelation.T, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find autocorrelation maxima and place field radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "def find_maxima(image):\n",
    "    image_max = filters.maximum_filter(image, 3)\n",
    "    is_maxima = (image == image_max)\n",
    "    labels, num_objects = ndimage.label(is_maxima)\n",
    "    indices = np.arange(1, num_objects+1)\n",
    "    maxima = ndimage.maximum_position(image, labels=labels, index=indices)\n",
    "    maxima = np.array(maxima)\n",
    "    return maxima\n",
    "\n",
    "maxima = find_maxima(autocorrelation)\n",
    "\n",
    "plt.imshow(autocorrelation.T, origin=\"lower\")\n",
    "plt.scatter(maxima[:, 0], maxima[:, 1], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_field_radius(auto_correlation, maxima):\n",
    "    map_size = np.array(auto_correlation.shape)\n",
    "    center = map_size / 2\n",
    "    distances = np.linalg.norm(maxima - center, axis=1)\n",
    "    distances_sorted = sorted(distances)\n",
    "    min_distance = distances_sorted[1] # the first one is basically the center\n",
    "    return 0.7 * min_distance / 2 # 0.7 because that is what Ismakov et al. used\n",
    "\n",
    "radius = place_field_radius(autocorrelation, maxima)\n",
    "radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find rate map maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fields(rate_map, rate_map_maxima, radius):\n",
    "    plt.imshow(rate_map.T, origin=\"lower\")\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for point in rate_map_maxima:\n",
    "        ax.add_artist(plt.Circle(point, radius, edgecolor=\"r\", facecolor=\"#ff000022\"))\n",
    "        ax.add_artist(plt.Circle(point, 0.6, color=\"r\"))\n",
    "\n",
    "rate_map_maxima = find_maxima(rate_map)\n",
    "\n",
    "plot_fields(rate_map, rate_map_maxima, radius)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove fields that are too close to each other\n",
    "\n",
    "We take the distance between each field pair.\n",
    "When encountering a pair where the distance is smaller than the `place_field_radius`, we add it to a list of pairs to investigate.\n",
    "For each such pair, we remove the field with the lowest firing rate.\n",
    "This will leave the highest one when there are three or more fields close to each other.\n",
    "This is not ideal and should be addressed, but we leave it as is to reproduce the method of Ismakov et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([40, 23]) - np.array([46, 17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as spatial\n",
    "\n",
    "# TODO verify this for an example where there are fields too close\n",
    "def too_close_removed(rate_map, rate_map_maxima, place_field_radius):\n",
    "    result = []\n",
    "    rate_map_maxima_value = rate_map[tuple(rate_map_maxima.T)]\n",
    "    distances = spatial.distance.cdist(rate_map_maxima, rate_map_maxima)\n",
    "    too_close_pairs = np.where(distances < place_field_radius*2)\n",
    "    not_accepted = []\n",
    "    \n",
    "    for i, j in zip(*too_close_pairs):\n",
    "        if i == j:\n",
    "            continue\n",
    "            \n",
    "        if rate_map_maxima_value[i] > rate_map_maxima_value[j]:\n",
    "            not_accepted.append(j)\n",
    "        else:\n",
    "            not_accepted.append(i)\n",
    "        \n",
    "    for i in range(len(rate_map_maxima)):\n",
    "        if i in not_accepted:\n",
    "            continue\n",
    "        \n",
    "        result.append(rate_map_maxima[i])\n",
    "        \n",
    "    return np.array(result)\n",
    "\n",
    "rate_map_maxima_filtered = too_close_removed(rate_map, rate_map_maxima, radius)\n",
    "\n",
    "plt.imshow(rate_map.T, origin=\"lower\")\n",
    "plot_fields(rate_map, rate_map_maxima_filtered, radius)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove fields that are too small in value in comparison to max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This is not necessarily used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def too_small_removed(rate_map, maxima, threshold=0.5):\n",
    "    result = []\n",
    "    maxima_values = rate_map[tuple(maxima.T)]\n",
    "    result = maxima[np.where(maxima_values > maxima_values.mean() * threshold)]\n",
    "    return result\n",
    "\n",
    "rate_map_maxima_filtered_2 = too_small_removed(rate_map, rate_map_maxima_filtered)\n",
    "\n",
    "plt.imshow(rate_map.T, origin=\"lower\")\n",
    "plot_fields(rate_map, rate_map_maxima_filtered_2, radius)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Find the peak rates at the remaining indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_map_maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_map_maxima_value = rate_map[tuple(rate_map_maxima_filtered.T)]  # picks values in points\n",
    "rate_map_maxima_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cv(in_array):\n",
    "    SD = np.std(in_array)\n",
    "    mean = np.mean(in_array)\n",
    "    CV = SD/mean\n",
    "    return CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_cv = find_cv(rate_map_maxima_value)\n",
    "field_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify rate maps\n",
    "\n",
    "To manually verify that the rate maps look reasonable, we plot each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maxima(row, session_id):\n",
    "    action_id = row[session_id]\n",
    "    group = row['group']\n",
    "    unit = row['unit']\n",
    "    x, y, t, speed, sptr = load_data(action_id, group, unit)\n",
    "    rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "    autocorrelation = calculate_autocorrelation(rate_map)\n",
    "    autocorrelation_maxima = find_maxima(autocorrelation)\n",
    "    radius = place_field_radius(autocorrelation, autocorrelation_maxima)\n",
    "    rate_map_maxima = find_maxima(rate_map)\n",
    "    rate_map_maxima_filtered = too_close_removed(rate_map, rate_map_maxima, radius)\n",
    "    \n",
    "    maxima_count = len(rate_map_maxima)\n",
    "    filtered_maxima_count = len(rate_map_maxima_filtered)\n",
    "    \n",
    "    print(\"Radius is {}\".format(radius))\n",
    "    \n",
    "    print(\"Filtered {} of {} maxima\".format(\n",
    "        len(rate_map_maxima) - len(rate_map_maxima_filtered),\n",
    "        len(rate_map_maxima_filtered))\n",
    "    )\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(rate_map.T, origin=\"lower\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_fields(rate_map, rate_map_maxima_filtered, radius)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(autocorrelation.T, origin=\"lower\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Session 1:\")\n",
    "\n",
    "table.apply(lambda row: plot_maxima(row, 'session_1'), axis=1)\n",
    "\n",
    "print(\"Session 2:\")\n",
    "\n",
    "table.apply(lambda row: plot_maxima(row, 'session_2'), axis=1)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_cv(row, session_id):\n",
    "    action_id = row[session_id]\n",
    "    group = row['group']\n",
    "    unit = row['unit']\n",
    "    x, y, t, speed, sptr = load_data(action_id, group, unit)\n",
    "    rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "    autocorrelation = calculate_autocorrelation(rate_map)\n",
    "    maxima = find_maxima(autocorrelation)\n",
    "    radius = place_field_radius(autocorrelation, maxima)\n",
    "    rate_map_maxima = find_maxima(rate_map)\n",
    "    rate_map_maxima_filtered = too_close_removed(rate_map, rate_map_maxima, radius)\n",
    "    rate_map_maxima_value = rate_map[tuple(rate_map_maxima_filtered.T)]\n",
    "    field_cv = find_cv(rate_map_maxima_value)\n",
    "    return field_cv\n",
    "\n",
    "table['cv_1'] = table.apply(lambda row: row_cv(row, 'session_1'), axis=1)\n",
    "table['cv_2'] = table.apply(lambda row: row_cv(row, 'session_2'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['cv_diff'] = table['cv_2'] - table['cv_1']\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "control = table[table['Control'] == 1]\n",
    "chabc = table[table['Control'] == 0]\n",
    "\n",
    "print(control['cv_1'].mean(), control['cv_1'].std())\n",
    "print(chabc['cv_1'].mean(), chabc['cv_1'].std())\n",
    "print(ttest_ind(control['cv_1'], chabc['cv_1']))\n",
    "\n",
    "print(control['cv_diff'].mean(), control['cv_diff'].std())\n",
    "print(chabc['cv_diff'].mean(), chabc['cv_diff'].std())\n",
    "print(ttest_ind(control['cv_diff'], chabc['cv_diff']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating correlation coefficient within one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_first_vs_second_half(row, session_id):\n",
    "    action_id = row[session_id]\n",
    "    group = row['group']\n",
    "    unit = row['unit']\n",
    "    x, y, t, speed, sptr = load_data(action_id, group, unit)\n",
    "    \n",
    "    def split(arr):\n",
    "        midpoint = int(len(x) / 2)\n",
    "        return arr[:midpoint], arr[midpoint:]\n",
    "    \n",
    "    x1, x2 = split(x)\n",
    "    y1, y2 = split(y)\n",
    "    t1, t2 = split(t)\n",
    "    speed1, speed2 = split(speed)\n",
    "    \n",
    "    rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "    rate_map1 = calculate_rate_map(x1, y1, t1, speed1, sptr)\n",
    "    rate_map2 = calculate_rate_map(x2, y2, t2, speed2, sptr)\n",
    "    \n",
    "    # NOTE: Ismakov et al. uses only the first half to find the \"zone mat\"\n",
    "    autocorrelation = calculate_autocorrelation(rate_map)\n",
    "    autocorrelation_maxima = find_maxima(autocorrelation)\n",
    "    radius = place_field_radius(autocorrelation, autocorrelation_maxima)\n",
    "    rate_map_maxima = find_maxima(rate_map)\n",
    "    rate_map_maxima_filtered = too_close_removed(rate_map, rate_map_maxima, radius)\n",
    "    \n",
    "    maxima_count = len(rate_map_maxima)\n",
    "    filtered_maxima_count = len(rate_map_maxima_filtered)\n",
    "    \n",
    "    print(\"Radius is {}\".format(radius))\n",
    "    \n",
    "    print(\"Filtered {} of {} maxima\".format(\n",
    "        len(rate_map_maxima) - len(rate_map_maxima_filtered),\n",
    "        len(rate_map_maxima_filtered))\n",
    "    )\n",
    "    \n",
    "    rate_map_maxima_value1 = rate_map1[tuple(rate_map_maxima_filtered.T)]\n",
    "    rate_map_maxima_value2 = rate_map2[tuple(rate_map_maxima_filtered.T)]\n",
    "    field_cv1 = find_cv(rate_map_maxima_value1)\n",
    "    field_cv2 = find_cv(rate_map_maxima_value2)\n",
    "    \n",
    "    return field_cv1, field_cv2\n",
    "    \n",
    "list(cv_first_vs_second_half(first_row, \"session_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vs_second = table.apply(lambda row: pd.Series(cv_first_vs_second_half(row, 'session_1')), axis=1)\n",
    "table['cv_1_first'], table['cv_1_second'] = first_vs_second[0], first_vs_second[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"cv_1_first_second_diff\"] = table[\"cv_1_second\"] - table[\"cv_1_first\"]\n",
    "\n",
    "control = table[table['Control'] == 1]\n",
    "chabc = table[table['Control'] == 0]\n",
    "\n",
    "print(control['cv_1_first_second_diff'].mean(), control['cv_1_first_second_diff'].std())\n",
    "print(chabc['cv_1_first_second_diff'].mean(), chabc['cv_1_first_second_diff'].std())\n",
    "print(ttest_ind(control['cv_1_first_second_diff'], chabc['cv_1_first_second_diff']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the firing rates against each other and calculate r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_first_vs_second_half(row, session_id):\n",
    "    action_id = row[session_id]\n",
    "    group = row['group']\n",
    "    unit = row['unit']\n",
    "    x, y, t, speed, sptr = load_data(action_id, group, unit)\n",
    "    \n",
    "    def split(arr):\n",
    "        midpoint = int(len(x) / 2)\n",
    "        return arr[:midpoint], arr[midpoint:]\n",
    "    \n",
    "    x1, x2 = split(x)\n",
    "    y1, y2 = split(y)\n",
    "    t1, t2 = split(t)\n",
    "    speed1, speed2 = split(speed)\n",
    "    \n",
    "    rate_map = calculate_rate_map(x, y, t, speed, sptr)\n",
    "    rate_map1 = calculate_rate_map(x1, y1, t1, speed1, sptr)\n",
    "    rate_map2 = calculate_rate_map(x2, y2, t2, speed2, sptr)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"All\")\n",
    "    plt.imshow(rate_map.T, origin=\"lower\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"First half\")\n",
    "    plt.imshow(rate_map1.T, origin=\"lower\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Second half\")\n",
    "    plt.imshow(rate_map2.T, origin=\"lower\")\n",
    "    \n",
    "    # NOTE: Ismakov et al. uses only the first half to find the \"zone mat\"\n",
    "    autocorrelation = calculate_autocorrelation(rate_map)\n",
    "    autocorrelation_maxima = find_maxima(autocorrelation)\n",
    "    radius = place_field_radius(autocorrelation, autocorrelation_maxima)\n",
    "    rate_map_maxima = find_maxima(rate_map)\n",
    "    rate_map_maxima_filtered = too_close_removed(rate_map, rate_map_maxima, radius)\n",
    "    #rate_map_maxima_filtered = too_small_removed(rate_map, rate_map_maxima_filtered)\n",
    "    \n",
    "    maxima_count = len(rate_map_maxima)\n",
    "    filtered_maxima_count = len(rate_map_maxima_filtered)\n",
    "    \n",
    "    print(\"Radius is {}\".format(radius))\n",
    "    \n",
    "    print(\"Filtered {} of {} maxima\".format(\n",
    "        len(rate_map_maxima) - len(rate_map_maxima_filtered),\n",
    "        len(rate_map_maxima_filtered))\n",
    "    )\n",
    "    \n",
    "    rate_map_maxima_value1 = rate_map1[tuple(rate_map_maxima_filtered.T)]\n",
    "    rate_map_maxima_value2 = rate_map2[tuple(rate_map_maxima_filtered.T)]\n",
    "\n",
    "    reg = np.polyfit(rate_map_maxima_value1, rate_map_maxima_value2, 1)\n",
    "    p = np.poly1d(reg)\n",
    "    \n",
    "    x = np.linspace(0, rate_map_maxima_value1.max(), 10)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(rate_map_maxima_value1, rate_map_maxima_value2)\n",
    "    plt.plot(x, p(x))\n",
    "    plt.show()\n",
    "    \n",
    "    return p[1]\n",
    "    \n",
    "r_first_vs_second_half(first_row, \"session_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['r_first_vs_second_1'] = table.apply(lambda row: r_first_vs_second_half(row, 'session_1'), axis=1)\n",
    "table['r_first_vs_second_2'] = table.apply(lambda row: r_first_vs_second_half(row, 'session_2'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the r-value different from zero\n",
    "\n",
    "If yes, then there is a stable pattern in the firing rate of the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = table[table['Control'] == 1]\n",
    "chabc = table[table['Control'] == 0]\n",
    "\n",
    "# Combine data from all sessions\n",
    "# TODO this is cumbersome because we use relate_sessions - we could make this cleaner\n",
    "control_r = pd.concat([control[\"r_first_vs_second_1\"],\n",
    "                      control[\"r_first_vs_second_2\"]])\n",
    "\n",
    "chabc_r = pd.concat([chabc[\"r_first_vs_second_1\"],\n",
    "                    chabc[\"r_first_vs_second_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_1samp(control_r, 0.0))\n",
    "print(ttest_1samp(chabc_r, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the r-values for the groups significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r_first_vs_second control mean\", control_r.mean())\n",
    "print(\"r_first_vs_second chabc mean\", chabc_r.mean())\n",
    "\n",
    "print(ttest_ind(control_r, chabc_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate r across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_two_sessions(row, session_id_1, session_id_2):\n",
    "    action_id_1 = row[session_id_1]\n",
    "    action_id_2 = row[session_id_2]\n",
    "    group = row['group']\n",
    "    unit = row['unit']\n",
    "    \n",
    "    x1, y1, t1, speed1, sptr1 = load_data(action_id_1, group, unit)\n",
    "    x2, y2, t2, speed2, sptr2 = load_data(action_id_2, group, unit)\n",
    "    \n",
    "    rate_map1 = calculate_rate_map(x1, y1, t1, speed1, sptr1)\n",
    "    rate_map2 = calculate_rate_map(x2, y2, t2, speed2, sptr2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"First session\")\n",
    "    plt.imshow(rate_map1.T, origin=\"lower\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Second session\")\n",
    "    plt.imshow(rate_map2.T, origin=\"lower\")\n",
    "    \n",
    "    autocorrelation = calculate_autocorrelation(rate_map1)\n",
    "    autocorrelation_maxima = find_maxima(autocorrelation)\n",
    "    radius = place_field_radius(autocorrelation, autocorrelation_maxima)\n",
    "    rate_map_maxima = find_maxima(rate_map1)\n",
    "    rate_map_maxima_filtered = too_close_removed(rate_map1, rate_map_maxima, radius)\n",
    "    #rate_map_maxima_filtered = too_small_removed(rate_map1, rate_map_maxima_filtered)\n",
    "    \n",
    "    maxima_count = len(rate_map_maxima)\n",
    "    filtered_maxima_count = len(rate_map_maxima_filtered)\n",
    "    \n",
    "    print(\"Radius is {}\".format(radius))\n",
    "    \n",
    "    print(\"Filtered {} of {} maxima\".format(\n",
    "        len(rate_map_maxima) - len(rate_map_maxima_filtered),\n",
    "        len(rate_map_maxima_filtered))\n",
    "    )\n",
    "    \n",
    "    rate_map_maxima_value1 = rate_map1[tuple(rate_map_maxima_filtered.T)]\n",
    "    rate_map_maxima_value2 = rate_map2[tuple(rate_map_maxima_filtered.T)]\n",
    "\n",
    "    reg = np.polyfit(rate_map_maxima_value1, rate_map_maxima_value2, 1)\n",
    "    p = np.poly1d(reg)\n",
    "    \n",
    "    x = np.linspace(0, rate_map_maxima_value1.max(), 10)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(rate_map_maxima_value1, rate_map_maxima_value2)\n",
    "    plt.plot(x, p(x))\n",
    "    plt.show()\n",
    "    \n",
    "    return p[1]\n",
    "    \n",
    "r_two_sessions(first_row, \"session_1\", \"session_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['r_session_1_vs_session_2'] = table.apply(lambda row: r_two_sessions(row, 'session_1', \"session_2\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are the r-values different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = table[table['Control'] == 1]\n",
    "chabc = table[table['Control'] == 0]\n",
    "\n",
    "print(\"r_session_1_vs_session_2 control mean\", control['r_session_1_vs_session_2'].mean())\n",
    "print(\"r_session_1_vs_session_2 chabc mean\", chabc['r_session_1_vs_session_2'].mean())\n",
    "\n",
    "print(ttest_ind(control['r_session_1_vs_session_2'], chabc['r_session_1_vs_session_2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store results form table as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO make this an expipe function\n",
    "output_path = pathlib.Path(project_path) / \"actions\" / \"field_variability\" / \"data\"\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "field_variability.data[\"results\"] = \"results.csv\"\n",
    "table.to_csv(output_path / \"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store this notebook to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_variability.data[\"notebook\"] = \"field_variability.ipynb\"\n",
    "shutil.copy(\"field_variability.ipynb\", output_path / \"field_variability.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As HTML\n",
    "os.system('jupyter nbconvert --to html field_variability.ipynb')\n",
    "field_variability.data[\"html\"] = \"field_variability.html\"\n",
    "shutil.copy(\"field_variability.html\", output_path / \"field_variability.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
